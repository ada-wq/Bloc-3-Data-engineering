# ğŸ“¦ Bloc 3 - ImplÃ©mentation et Optimisation de Solutions de Stockage et de Traitement de DonnÃ©es sur le Cloud

## ğŸ¯ Objectif du projet

Ce projet a pour but de concevoir, implÃ©menter et optimiser une solution cloud de traitement et de visualisation de donnÃ©es pour une **Ã©cole de danse**. L'ensemble de l'architecture repose sur **Microsoft Fabric**, combinant un **Data Lake moderne** au format **Delta Lake**, une approche **ETL robuste**, et des tableaux de bord interactifs via **Power BI**.

---

## ğŸ—ï¸ Architecture Technique

### ğŸ”§ Choix technologiques
- **Microsoft Fabric** : unification du stockage, traitement et visualisation
- **PySpark** : traitement distribuÃ© des donnÃ©es
- **Delta Lake** : stockage versionnÃ© et performant
- **Power BI** : visualisation des KPI mÃ©tiers
- **Lakehouse Architecture** : flexibilitÃ© du data lake et structure du data warehouse

---

## ğŸ“ DonnÃ©es Sources

| Fichier | Description |
|--------|-------------|
| `danseurs.csv` | Informations clients (personnelles et marketing) |
| `inscriptions.csv` | Historique des inscriptions |
| `tarifs.csv` | Grille tarifaire |
| `formule.csv` | Types de formules proposÃ©es |
| `duree.csv` | DurÃ©e des cours |
| `danse.csv` | Catalogue des danses enseignÃ©es |

---

## ğŸ§  ModÃ©lisation des DonnÃ©es

### ğŸ§© ModÃ¨le en Ã‰toile
- **Table de faits** : `FAIT_INSCRIPTIONS`
- **Dimensions** : clients, danses, formules, durÃ©es, tarifs, temps

### ğŸ•“ Gestion de lâ€™historique
- `SCD Type 2` : pour `DIM_DANSEUR` (versioning)
- `SCD Type 1` : pour `DIM_FORMULE` (mise Ã  jour simple)

### ğŸ·ï¸ Enrichissement
- `DIM_TARIF` enrichie avec formules, durÃ©es et types de danse

---

## ğŸ”„ Pipeline ETL

- **Zone Staging** : ingestion et nettoyage des CSV
- **Transformation mÃ©tier** :
  - Calcul du nombre de sÃ©ances
  - Calcul de rentabilitÃ©, coÃ»t unitaire, CA
- **Dimension temporelle dynamique** : aoÃ»t 2024 Ã  juillet 2025

---

## ğŸ’¾ Stockage & SÃ©curitÃ©

- **Organisation Data Lake** : Raw â†’ Staging â†’ Gold
- **Formats supportÃ©s** : CSV, Delta, JSON
- **Change Data Feed** + sauvegarde incrÃ©mentale
- **SÃ©curitÃ©** :
  - Chiffrement au repos et en transit
  - Hachage des donnÃ©es sensibles
  - ConformitÃ© RGPD (anonymisation, suppression logs, rÃ©tention diffÃ©renciÃ©e)

---

## ğŸ“Š Visualisation avec Power BI

Des dashboards dynamiques ont Ã©tÃ© construits :
- CA par type de danse
- RÃ©partition des inscriptions par formule
- Suivi de la fidÃ©litÃ© client
- PÃ©riodes de pic dâ€™activitÃ©

### ğŸ“ˆ KPI suivis :
- Ã‰volution mensuelle du chiffre d'affaires
- Taux de rÃ©tention client
- RentabilitÃ© par formule
- PrÃ©vision des inscriptions

---

## ğŸ” Monitoring & Optimisation

- **ObservabilitÃ©** :
  - Logs centralisÃ©s
  - Alertes en cas dâ€™anomalie
  - Suivi des performances
- **Optimisations** :
  - Auto-compaction
  - Z-ordering
  - Vacuum automatique
  - Ajustement des ressources Spark

---

## ğŸ› ï¸ DÃ©fis rencontrÃ©s

| DÃ©fi | Solution |
|------|----------|
| ProblÃ¨mes d'encodage | Fonction de nettoyage personnalisÃ©e |
| Logique mÃ©tier complexe | Expressions rÃ©guliÃ¨res & conditions personnalisÃ©es |
| Historisation SCD | Algorithme de dÃ©tection des changements via jointure intelligente |

---

## âœ… CritÃ¨res Bloc 3 ValidÃ©s

- âœ”ï¸ Architecture Data Lake multi-format
- âœ”ï¸ Pipelines ETL cloud robustes
- âœ”ï¸ SÃ©curitÃ© et RGPD respectÃ©s
- âœ”ï¸ Monitoring & optimisation des coÃ»ts
- âœ”ï¸ Visualisations dynamiques pour les mÃ©tiers

---

## ğŸ“Œ Conclusion

Ce projet dÃ©montre une **maÃ®trise complÃ¨te** de la chaÃ®ne de traitement de donnÃ©es sur le cloud :

- Architecture scalable & moderne
- Pipelines mÃ©tiers solides
- Gouvernance et conformitÃ© intÃ©grÃ©es
- Visualisations percutantes pour les utilisateurs mÃ©tiers

---

## ğŸ“‚ Contenu du dÃ©pÃ´t

- `Stagingsdcdatawarehouse.ipynb` : pipeline PySpark
- `rapportanalysedance.pbix` : rapport Power BI
- `Modele semantique.png` : diagramme du modÃ¨le en Ã©toile

---

## ğŸ‘¤ Auteur

> [@ada-wq](https://github.com/ada-wq) â€“ Projet rÃ©alisÃ© dans le cadre du Bloc 3 Data Engineering Ã  lâ€™EFREI
